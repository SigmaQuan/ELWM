# External Long-term and Working Memory augmented Recurrent Neural Networks (ELWM-RNNs)

Experiment on External Long-term and Working Memory augmented Recurrent Neural Networks (ELWM-RNNs).


## Prerequisties
- Python 2.7
- [Theano](https://github.com/Theano/Theano)
- [Keras](https://github.com/fchollet/keras)



## Experiment on algorithm learning
**Copy**
![alt_tag](unit_test/image/figure_4.png)
**NTM Memory Use During the Copy Task**
![alt_tag](unit_test/image/figure_6.png)

**Repeat Copy**
(in progress)

**Associative Recall**
(in progress)

**Dynamic N-Grams**
(in progress)

**Priority Sort**
(in progress)



## Experiment on language modeling
**PTB**
(in progress)

**Text8**
(in progress)

**CBT**
(in progress)



## Experiment on question answering 
**bAbI**
(in progress)


## Usage
To train a copy task:
```
    $ python main.py
```


## Future works
- Training ELWM-RNNs with reinforcement learning method.
- Using ELWM-RNNs for other natural language processing tasks.k


## Author
Zhibin Quan / [@SigmaQuan](https://github.com/SigmaQuan)
